---
title: "Caso APlicado Jep"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

¿Cómo leer sus documentos?

Toca por OCR

OCR: optical character recognition, es un modelo de Machine Learning de reconocimiento de caracteres basado en fuerza bruta ( es un proceso sumamente demorado)

```{r}
library(tesseract)
library(pdftools)
library(tidytext)
library(tidyverse)
library(magick)
eng <- tesseract("spa") # Se define el idioma
```

Se genera la lectura del documento 

```{r}
input <- image_read("~/Desktop/Bases_JEP/2015-00153_CAJA_2-9_CUADERNILLO--14.pdf")
```



```{r}
text <- input %>%
  image_resize("2000x") %>%
  image_convert(type = 'Grayscale') %>%
  image_trim(fuzz = 40) %>%
  image_write(format = 'png', density = '300x300') %>%
  tesseract::ocr() 

cat(text)
```


Por lo visto, esta no es la mejor opción!

Otra forma de hacerlo es :

```{r}
pngfile <- pdftools::pdf_convert('~/Desktop/Bases_JEP/2015-00153_CAJA_2-9_CUADERNILLO--14.pdf', dpi = 600)

text <- tesseract::ocr(pngfile)
cat(text)
```

```{r}
file_list<- list.files(path = "~/Desktop/Bases_JEP/2015-00153_CAJA_2-9_CUADERNILLO--14.pdf")
pdf_list="~/Desktop/Bases_JEP/2015-00153_CAJA_2-9_CUADERNILLO--14.pdf"

corpus_raw <- data.frame("documento" = c(),"text" = c())

for (i in pdf_list){
  setwd("~/Desktop/Bases_JEP/")
  print(i)
  tesseract::ocr(i, engine = eng)%>%
  strsplit("\n")-> document_text 
  data.frame("documento" = gsub(x =i,pattern = ".pdf", replacement = ""), 
             "text" = document_text%>%unlist(), stringsAsFactors = FALSE) -> document
  colnames(document) <- c("Peru", "text")
  corpus_raw <- rbind(corpus_raw,document) 
}
corpus_raw
```

Trabajo poir OCR persona
Javier : primer documento
jorge : el segundo documento 
Juan David tercer documento
Klendia: Cuarto documento
Luis Ernesto : Quinto Documento
Mary - Sandra -Zulma : Sexto Documento
